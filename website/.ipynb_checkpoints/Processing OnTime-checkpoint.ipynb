{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This notebook was used to test the transformations of the dataset and to test machine learning models\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/opt/spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkFiles\n",
    "spark = SparkSession.builder.appName('OnTimeProcess_byriel').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('final_2020_*.csv', header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "210"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupBy('Dest').count().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dest',\n",
       " 'ArrDelayMinutes',\n",
       " 'Diverted',\n",
       " 'Cancelled',\n",
       " 'WeatherDelay',\n",
       " 'temp',\n",
       " 'dewpoint',\n",
       " 'wind',\n",
       " 'precip',\n",
       " 'alti',\n",
       " 'vis',\n",
       " 'cloudCoverage',\n",
       " 'cloudAlt',\n",
       " 'weather',\n",
       " 'ice']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder\n",
    "\n",
    "cloudIndex = StringIndexer(inputCol='cloudCoverage', outputCol='cloudIndex')\n",
    "cloudOnehot = StringIndexer(inputCol='cloudIndex', outputCol='cloudOnehot')\n",
    "weatherIndex = StringIndexer(inputCol='weather', outputCol='weatherIndex')\n",
    "weatherOnehot = StringIndexer(inputCol='weatherIndex', outputCol='weatherOnehot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cloudIndex.fit(data).transform(data)\n",
    "data = cloudOnehot.fit(data).transform(data)\n",
    "data = weatherIndex.fit(data).transform(data)\n",
    "data = weatherOnehot.fit(data).transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(inputCols=[\n",
    "    'temp',\n",
    "    'dewpoint',\n",
    "    'wind',\n",
    "    'precip',\n",
    "    'alti',\n",
    "    'vis',\n",
    "    'cloudOnehot',\n",
    "    'cloudAlt',\n",
    "    'weatherOnehot',\n",
    "    'ice'\n",
    "], outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = assembler.transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = data.select(['ArrDelayMinutes',\n",
    " 'Diverted',\n",
    " 'Cancelled',\n",
    " 'WeatherDelay',\n",
    " 'features'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----+\n",
      "|Diverted|count|\n",
      "+--------+-----+\n",
      "|     0.0|88897|\n",
      "|     1.0|  195|\n",
      "+--------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml.groupBy('Diverted').count().show()\n",
    "\n",
    "dones = ml.filter(ml['Diverted'] == 1).count()\n",
    "dzeros = ml.filter(ml['Diverted'] == 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "divertWeights = udf(lambda x: dzeros/(dones+dzeros) if x == 1.0 else dones/(dones+dzeros), DoubleType())\n",
    "ml = ml.withColumn('divertWeight', divertWeights(ml['Diverted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|Cancelled|count|\n",
      "+---------+-----+\n",
      "|      0.0|88513|\n",
      "|      1.0|  579|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml.groupBy('Cancelled').count().show()\n",
    "\n",
    "cones = ml.filter(ml['Cancelled'] == 1).count()\n",
    "czeros = ml.filter(ml['Cancelled'] == 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancelWeights = udf(lambda x: czeros/(cones+czeros) if x == 1.0 else cones/(cones+czeros), DoubleType())\n",
    "ml = ml.withColumn('cancelWeight', divertWeights(ml['Cancelled']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "isWxDelay = udf(lambda x: 0.0 if x == 0.0 else 1.0, DoubleType())\n",
    "ml = ml.withColumn('hasWXDelay', isWxDelay(ml['WeatherDelay']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|hasWXDelay|count|\n",
      "+----------+-----+\n",
      "|       0.0|88259|\n",
      "|       1.0|  833|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml.groupBy('hasWXDelay').count().show()\n",
    "\n",
    "wones = ml.filter(ml['hasWXDelay'] == 1).count()\n",
    "wzeros = ml.filter(ml['hasWXDelay'] == 0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancelWeights = udf(lambda x: wzeros/(wones+wzeros) if x == 1.0 else wones/(wones+wzeros), DoubleType())\n",
    "ml = ml.withColumn('wxdWeight', divertWeights(ml['hasWXDelay']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = ml.randomSplit([0.7, 0.3], seed=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "divertLR = LogisticRegression(featuresCol='features', labelCol='Diverted', weightCol='divertWeight')\n",
    "cancelLR = LogisticRegression(featuresCol='features', labelCol='Cancelled', weightCol='cancelWeight')\n",
    "delayLR = LogisticRegression(featuresCol='features', labelCol='hasWXDelay', weightCol='wxdWeight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "divertModel = divertLR.fit(train)\n",
    "cancelModel = cancelLR.fit(train)\n",
    "delayModel = delayLR.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "divertResult = divertModel.transform(test)\n",
    "    #Area Under ROC: about .6\n",
    "    #Accuracy: About 0.4\n",
    "cancelResult = cancelModel.transform(test)\n",
    "    #Area Under ROC: about 0\n",
    "    #Accuracy: About .99\n",
    "delayResult = delayModel.transform(test)\n",
    "    #Area Under ROC: about .7\n",
    "    #Accuracy: About 0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "divert 0.7859548039509129\n",
      "divert roc 0.5762919276330207\n",
      "cancel 0.024431307991619276\n",
      "delay 0.00924124513618677\n"
     ]
    }
   ],
   "source": [
    "print('divert lr accuracy',divertModel.evaluate(test).accuracy)\n",
    "print('divert roc', divertModel.evaluate(test).areaUnderROC)\n",
    "print('cancel lr accuracy',cancelModel.evaluate(test).accuracy)\n",
    "print(\"delay lr accuracy\",delayModel.evaluate(test).accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+---------+------------+-----------------------------------------------+--------------------+--------------------+----------+--------------------+\n",
      "|ArrDelayMinutes|Diverted|Cancelled|WeatherDelay|features                                       |divertWeight        |cancelWeight        |hasWXDelay|wxdWeight           |\n",
      "+---------------+--------+---------+------------+-----------------------------------------------+--------------------+--------------------+----------+--------------------+\n",
      "|0.0            |0.0     |0.0      |0.0         |(10,[2,4,5,6,7],[2.0,29.79,10.0,2.0,6000.0])   |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|9.0            |0.0     |0.0      |0.0         |(10,[2,4,5,6,7],[8.0,30.21,10.0,4.0,12000.0])  |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|18.0           |0.0     |0.0      |0.0         |(10,[2,4,5,6,7],[5.0,30.38,10.0,1.0,3700.0])   |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|0.0            |0.0     |0.0      |0.0         |(10,[2,4,5],[5.0,30.39,10.0])                  |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|10.0           |0.0     |0.0      |0.0         |(10,[2,4,5,6,7],[4.0,30.12,10.0,1.0,6000.0])   |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|0.0            |0.0     |0.0      |0.0         |(10,[2,4,5,6,7],[5.0,29.97,10.0,3.0,2900.0])   |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|0.0            |0.0     |0.0      |0.0         |(10,[2,4,5,6,7],[7.0,29.89,8.0,1.0,1100.0])    |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|0.0            |0.0     |0.0      |0.0         |(10,[2,4,5,6,7],[11.0,30.26,10.0,1.0,1100.0])  |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|6.0            |0.0     |0.0      |0.0         |[0.0,0.0,10.0,0.03,30.22,5.0,1.0,999.0,7.0,0.0]|0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|0.0            |0.0     |0.0      |0.0         |(10,[2,4,5],[5.0,30.6,10.0])                   |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|0.0            |0.0     |0.0      |0.0         |(10,[4,5],[30.51,10.0])                        |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|0.0            |0.0     |0.0      |0.0         |(10,[2,4,5,6],[5.0,30.24,10.0,5.0])            |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|0.0            |0.0     |0.0      |0.0         |(10,[2,4,5,6,7],[5.0,29.92,10.0,1.0,4200.0])   |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|0.0            |0.0     |0.0      |0.0         |(10,[2,4,5],[4.0,29.83,10.0])                  |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|0.0            |0.0     |0.0      |0.0         |(10,[2,4,5,6,7],[5.0,30.06,10.0,3.0,12000.0])  |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|0.0            |0.0     |0.0      |0.0         |(10,[2,4,5],[2.0,30.41,10.0])                  |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|0.0            |0.0     |0.0      |0.0         |(10,[2,4,5],[7.0,30.28,10.0])                  |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|0.0            |0.0     |0.0      |0.0         |(10,[4,5],[30.32,10.0])                        |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|0.0            |0.0     |0.0      |0.0         |(10,[2,4,5],[9.0,30.14,10.0])                  |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "|7.0            |0.0     |0.0      |0.0         |(10,[2,4,5,6,7],[4.0,29.85,10.0,3.0,5000.0])   |0.002188748709199479|0.002188748709199479|0.0       |0.002188748709199479|\n",
      "+---------------+--------+---------+------------+-----------------------------------------------+--------------------+--------------------+----------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ml.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "#delay with random forests\n",
    "delayForest = RandomForestClassifier(labelCol='hasWXDelay', weightCol='wxdWeight', maxBins = 100)\n",
    "delayRF = delayForest.fit(train)\n",
    "delayRFResult = delayRF.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='hasWXDelay', weightCol='wxdWeight', metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8040839223647489"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(delayRFResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7960611093168654\n"
     ]
    }
   ],
   "source": [
    "#cancellations with random forest\n",
    "cancelForest = RandomForestClassifier(labelCol='Cancelled', weightCol='cancelWeight', maxBins = 100)\n",
    "cancelRF = cancelForest.fit(train)\n",
    "cancelRFResult = cancelRF.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='Cancelled', weightCol='cancelWeight', metricName='accuracy')\n",
    "print(evaluator.evaluate(cancelRFResult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4769990505334242\n"
     ]
    }
   ],
   "source": [
    "#diversions with random forest\n",
    "divertForest = RandomForestClassifier(labelCol='Diverted', weightCol='divertWeight', maxBins = 100)\n",
    "divertRF = divertForest.fit(train)\n",
    "divertRFResult = divertRF.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='Diverted', weightCol='divertWeight', metricName='accuracy')\n",
    "print(evaluator.evaluate(delayRFResult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import GBTClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8113088997734172\n"
     ]
    }
   ],
   "source": [
    "#cancellations with GBT\n",
    "cancelGBT = GBTClassifier(labelCol='Cancelled', weightCol='cancelWeight', maxBins = 100)\n",
    "cancelGB = cancelGBT.fit(train)\n",
    "cancelGBTResult = cancelGB.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='Cancelled', weightCol='cancelWeight', metricName='accuracy')\n",
    "print(evaluator.evaluate(cancelGBTResult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7541158961473642\n"
     ]
    }
   ],
   "source": [
    "#delay with GBT\n",
    "delayGBT = GBTClassifier(labelCol='hasWXDelay', weightCol='wxdWeight', maxBins = 100)\n",
    "delayGB = delayGBT.fit(train)\n",
    "delayGBTResult = delayGB.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='hasWXDelay', weightCol='wxdWeight', metricName='accuracy')\n",
    "print(evaluator.evaluate(delayGBTResult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#diversions with GBT\n",
    "divertGBT = GBTClassifier(labelCol='Diverted', weightCol='divertWeight', maxBins = 100)\n",
    "divertGB = divertGBT.fit(train)\n",
    "divertGBTResult = divertGB.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='Diverted', weightCol='divertWeight', metricName='accuracy')\n",
    "print(evaluator.evaluate(divertGBTResult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7706661792350311\n"
     ]
    }
   ],
   "source": [
    "#Delay with decision tree\n",
    "delayTree = DecisionTreeClassifier(labelCol='hasWXDelay', weightCol='wxdWeight', maxBins = 100)\n",
    "delayTM = delayTree.fit(train)\n",
    "delayTreeResult = delayTM.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='hasWXDelay', weightCol='wxdWeight', metricName='accuracy')\n",
    "print(evaluator.evaluate(delayTreeResult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5557437026590059\n"
     ]
    }
   ],
   "source": [
    "#Diversion with decition tree\n",
    "divertTree = DecisionTreeClassifier(labelCol='Diverted', weightCol='divertWeight', maxBins = 100)\n",
    "divertTM = divertTree.fit(train)\n",
    "divertTreeResult = divertTM.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='Diverted', weightCol='divertWeight', metricName='accuracy')\n",
    "print(evaluator.evaluate(divertTreeResult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.790692218774066\n"
     ]
    }
   ],
   "source": [
    "#Cancellation with decision tree\n",
    "cancelTree = DecisionTreeClassifier(labelCol='Cancelled', weightCol='cancelWeight', maxBins = 100)\n",
    "cancelTM = cancelTree.fit(train)\n",
    "cancelTreeResult = cancelTM.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol='Cancelled', weightCol='cancelWeight', metricName='accuracy')\n",
    "print(evaluator.evaluate(cancelTreeResult))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Final choices:\n",
    "#Diversion: Logistic Regression\n",
    "#Cancel: GBT\n",
    "#wxDelay: Random Forest "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
